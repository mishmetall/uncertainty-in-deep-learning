Неопределенность в машинном обучении

Ярин Гал

Департамент инженерии Кэмбриджского университета


Реферат

Глубокое обучение привлекло огромное внимание исследователей из множества областей информационной инженерии, таких как ИИ, машинное зрение, обработка языка [Kalchbrenner and Blunsom, 2013; Krizhevsky et al., 2012; Mnih et al., 2013], а также из более традиционных областей знаний, таких как физика, биология и промышленность [Anjos et al., 2015; Baldi et al., 2014; Bergmann et al., 2014]. Нейронные сети, средства обработки изображений, такие как сверточные нейронные сети, модели для обработки последовательностей, такие как рекуррентные нейронные сети, средства для регуляризации, такие как дропаут, нашли широкое применение. Однако, в таких области как физика, биология, промышленность выражение неопределенности модели является критически важным [Ghahramani, 2015; Krzywinski and Altman, 2013]. Начиная с недавнего сдвига этих областей в сторону использования Баесовской неопределенности [Herzog and Ostwald, 2013; Nuzzo, 2014; Trafimow and Marks, 2015], такая потребность возникла и у глубокого обучения.
В данной работе мы разработали метод для практического определения неопределенности в глубоком обучении, преподнося методы глубокого обучения как Баесовские модели без изменения как самих моделей таки и методов оптимизации. В первой части этой работы мы разработаем теорию метода, а также предоставим иллюстрации и примеры использования. Мы свяжем приближенный вывод в Баесовских моделях с дропаутом и другими стохастическими методами регуляризации, а также оценим данное приближение эмпирически. Мы приведем примеры приложений, которые проистекают из связи между современным глубоким обучением и баесовскими моделями такими как активное обучение на изображениях, а также эффективное с точки зрения данных обучение с подкреплением. Далее мы демонстрируем метод на практике путем рассмотрения ряда приложений, использующих на практике разработанный метод, таких как обработка речи, медицинская диагностика, биоинформатика, обработка изображений, беспилотное управление автомобилем. Во второй части данной работы мы исследуем данные проистекающие от связи Баесовского моделирования с глубоким обучением и их теоретические следствия. Мы исследуем что же определяет свойство неопределенности, анализируем приближенный вывод аналитически в линейных случаях и теоретически исследуем различные априорные вероятности, такие как вероятности всплесков и плато.


Глава 1

Вступление:
Важность знания того чего мы не знаем

В баесовском машинном обучении мы работаем с вероятностными моделями и неопределенностью. Модели, такие как гауссов процесс, которые определяют вероятностное распределение на функциях, используются для обучения более и менее вероятных путей к обобщению по наблюдаемым данным. Этот вероятностный подход к машинному обучению дает доверительные границы для анализа данных и принятия решений, информация, на которую будет полагаться, к примеру, биолог чтобы анализировать свои данные, или беспилотный автомобиль использует чтобы понять когда нужно жать на тормоз. В анализе данных или же принятии решений часто требуется определить степень с которой модель уверена в своем результате, быть способным задать вопрос "может мне нужно использовать более разнообразные данные? или поменять модель? или может быть более внимательным при принятии решений?". Такие вопросы являются фундаментальными в баесовском машинном обучении и были изучены тщательно в данной области [Ghahramani, 2015]. Когда же мы используем модели глубокого обучения [Goodfellow et al., 2016], мы обычно имеем точечную оценку параметров и предсказаний. Использование таких моделей заставляет нас пожертвовать методом, позволяющим получить ответ на выше заданные вопросы, потенциально приводя к ситуациям, когда мы не можем сказать дает ли модель разумное предсказание или просто угадывает.
	Большинство моделей глубокого обучения обычно рассматриваются как детерминистические функции, и как следствие рассматриваются как работа в совершенно другом поле по сравнению с вероятностными моделями, которые оперируют информацией о неопределенности. Вероятно по этой причине довольно неожиданно видеть как близки современные методы глубокого обучения к вероятностному моделированию. Фактически, мы можем увидеть что мы можем получить информацию об неопределенности из существующих моделей глубокого обучения без каких-либо изменений. Главной целью данной работы является разработка такого практического способа для получения информации о неопределенности в глубоком обучении.


1.1 Глубокое обучение

	Чтобы рассказать о глубоком обучении, я бы начал с рассмотрения простейшей статистической модели: линейной регрессии [Gauss, 1809; Legendre, 1805; Seal, 1967]. В линейной регрессии мы имеем N пар входов и выходов {(x1, y1), ...,(xN , yN )}, для примера измерения температуры газа CO2, или среднее число аварий при разных скоростях движения. Мы предполагаем, что существует линейная функция, которая отображает каждый xi ∈ R^Q на yi ∈ R^D (при этом yi потенциально содержит в себе ошибку измерений). В таком случае наша модель является линейной трансформацией входов: f(x) = xW + b, где W - некая матрица размера QxD вещественных чисел и b - вектор вещественных чисел из D элементов. Разные параметры W, b определяют различные линейные трансформации, а нашей целью является найти такие параметры которые, к примеру, будут минимизировать среднеквадратичное отклонение относительно имеющихся данных наблюдейний 1/N \sum_i {||yi − (xiW + b)||2}. 
	В более общих случаях, где связь между x и y не должна быть линейной, мы можем ввести нелинейную функцию f(x), которая отображает входы на выходы. Для этого мы прибегнем к помощи регрессии с линейными базисными функциями [Bishop, 2006; Gergonne, 1815; Smith, 1918], где вход x подставляется в K фиксированных нелинейных преобразования ϕk(x) чтобы получить вектор Φ(x) = [ϕ1(x), ..., ϕK(x)]. Затем мы ищем линейную регрессию с этим вектором, вместо вектора x. Трансформации ϕk являются нашими базисными функциями, и имея скалярные значения x, они могут быть вейвлет-параметризованы по k, полиномами разной степени x^k или синусоидами с разными частотами. Когда ϕk(x) := x_k и K = Q, регрессия по базисным функциям сводится к линейной регрессии. Базисные функции часто берутся фиксированными и ортогональными друг к другу, а затем находится их оптимальная комбинация.
	Упраздняя ограничение на фиксированность и взаимную ортогональность базисных функций мы получаем параметризированные базисные функции [Bishop, 2006]. Например, мы можем определить базисные функции как ϕ_k^w_k,b_k, где функция скалярного значения ϕ_k применяется к скалярному произведению ⟨wk, x⟩ + bk. В данном случае ϕ_k часто задаются идентичными для всех k, например ϕ_k(·) = sin(·) при ϕ_k^wk,bk(x) = sin(⟨wk, x⟩ + bk). Вектор признаков, сформированный из выходов базисных функций затем вновь используется как вход в линейной трансформации. Таким образом, выход модели может быть более компактно записан как f(x) = Φ^{W1,b1}(x)W2 + b2 с
Φ^{W1,b1}(x) = ϕ(W1x + b1), где W1 - матрица размерности QхK, b1 - вектор из K элементов, W2 -матрица размерности  KхD, и b2 - вектор длины D. Чтобы найти регрессию теперь нам нужно найти W1, b1, а также W2 и b2, которые минимизируют среднеквадратичную ошибку на наблюдаемых данных, ||y − f(x)||2.
	Наиболее простая модель в глубоком обучении может быть описана как иерархия таких параметризованных функций (такая иерархия называется нейронной сетью по историческим причинам, где каждый вектор фич в иерархии назван слоем). В простейшей конфигурации регрессии мы просто скомбинируем множество регрессионных моделей базисных функций, а для классификации мы добавим в конец логистическую функцию (которая "сожмет" выход линейной модели для получения вектора вероятностей). Каждый слой в иерархии может быть рассмотрен как строительный блок, а модульность в такой композиции обуславливает универсальность моделей глубокого обучения. Простота каждого блока, вместе с возможностью комбинировать модели, должно быть, явилось причиной, по которой многие инженеры решили работать в данной области. Это привело к успешной разработке методов которые хорошо работают и масштабируются.
	Мы продолжим обзор простых моделей нейронных сетей, связывая нотацию из области глубокого обучения и математический формализм вышеописанной модели регрессии базисных функций. Затем мы расширим их на специализирвоанные модели, спроектированные для обработки изображений и последовательностей данных. В ходе изложения мы введем терминологию и математическую нотаацию, которая будет использована в дальнейшем в работе. Мы опишем модели формально, но сжато, что позволит нам продолжить наше повествование во вступлении используя более точный язык.

	Нейронные сети обратного распространения ошибки (НС). Вначале рассмотрим модель нейронной сети [Rumelhart et al., 1985] с одним скрытым слоем. Это сделано для упрощения записи, а обобщение к многослойной архитектуре тривиально. Обозначим x как вход модели (известный как входной слой, вектор из Q элементов) и с помощью аффинного преобразования приведем его к вектору из K элементов. Обозначим W1 как линейное отображение (известное как матрица весов) и b - смещение (известное как баес), используемые для трансформации входа x чтобы получить xW1 + b. Поэлементная нелинейность σ(·) (такая как ректифицированный линейный ReLU) или TanH)  затем применяется к результату, формируя скрытый слой, где каждый элемент называется нейроном. Дальше следует второй слой с матрицей преобразования W2, отображая скрытый слой модели на выход модели (известный как выходной слой, вектор длины D). Эти два слоя также известны как полносвязные слои. Таким образом мы имеем W1 - матрица QxK, W2 - матрица KxD и b - вектор размера K. Стандартная сеть порождает следующий выход:
							yb = σ(xW1 + b)W2
получая на входе x.
	Для использования сети в задаче регрессии мы можем использовать Евклидову функцию потерь,
			E^{W1,W2,b}(X, Y) = 1/2N \sum{i=1..N}(||yi − ybi||^2)                           (1.1)
где {y1, ..., yN} - N выходов, а {yb1, ..., ybN } - выходы модели на соответствующих входах {x1, ..., xN }. Минимизируя эту функцию потерь относительно параметров W1,W2, b мы надеемся получить модель, которая будет хорошо предсказывать тестовые данные Xtest, Ytest.
	Для использования этой модели в классификации, имея классы в множестве {1, ..., D}, мы используем функцию софтмакса на выходах yb для получения нормализованных оценок : pb^d = exp(yb^d)/ (\sum{d′}(exp(yb^d′)). Если же мы логарифмируем pb^d (где d - наблюдаемый класс), то получим функцию потерь softmax,
                      E^{W1,W2,b}(X, Y) = −1/N \sum{i=1..N}(log(pbi,di))                                (1.2)
где di ∈ {1, 2, ..., D} - наблюдаемый класс для измерения i.
	Большая сложность с моделями выше в том, что они имеют тенденцию к переобучению - снижению функции потерь на тренировочных данных X, Y при одновременном увеличении таковой на тестовых данных Xtest, Ytest. По этой причине вводится член регуляризации во время оптимизации.Обычно используется L2 регуляризация для каждого параметра, взвешенная некоторым весом λi, получая следующую функцию потерь:
                      L(W1,W2, b) := E^{W1,W2,b}(X, Y) + λ1||W1||^2 + λ2||W2||^2 + λ3||b||^2.           (1.3)
Описанная выше однослойная НС с евклидовской функцией потерь идентичная регрессионной модели базисных функций. Расширяя эту простую модель до многослойной НС, получаем модель с большей выразительной способностью.

Замечание (выразительная способность модели): Интуитивное определение выразительной способности можно определить как сложность функции, которую может аппроксимировать модель (определяя что сложная функция не тривиальна сама по себе, хотя когда говорим о полиномах такие более высоких порядков считаются более сложными чем полиномы более низких порядков). По этой логике, иерархические модели базисных функций являются более выразительными чем их "плоские" аналоги. Интересно заметить, что и хотя "плоские" регрессии базисных функций могут моделировать любую функцию с заданной точностью имея достаточное количество базисных функций [Cybenko, 1989; Hornik, 1991], используя иерархии мы можем использовать значительно более компактные модели.  Рассмотрим пример регрессии базисных функций с полиномиальными базисными функциями ϕ_k ∈ {1, x, x^2, ..., x^K−1}: множество функций, которые можно выразить используя эти K базисных функций есть {все полиномы порядка вплоть до K-1}. Комбинируя модель регрессии базисных функций L раз приводит нас к модели, которая может выразить (подмножество) функций из множества {все полиномы вплоть до степени (K-1)^L}. "Плоской" модели, способной выразить (K-1)^L, понадобиться K^L базисных функций, в то время как иерархическая модель с аналогичной (но не идентичной) выразительностью потребует KxL базисных функций. Выразительность моделей более деатально рассматривается в [Bengio and LeCun, 2007], к примеру, там рассматривается бинарные цепи для иллюстрации.

Эта простая структура, описанная выше, может быть расширена на специализированные модели, целью которых является работа с изображениями или последовательностями входных данных. Мы далее быстро рассмотрим их.

Сверточные нейронные сети (CNN). CNN [LeCun et al., 1989; Rumelhart et al., 1985] являются популярной моделью глубокого обучения для обработки изображений, которая может решать задачи, которые ранее считались трудноразрешимыми[Krizhevsky et al., 2012; Szegedy et al., 2014]. Эти модели состоят из повторяющихся сверточных и пулинг слоев, за которыми следует полносвязный слой (обычная НС, описанная выше). Сверточный слой является линейной трансформацией, которая сохраняет пространсвенную информацию на изображении (как показано на рисунке 1.1). Пулинг-слой берет выход сверточного слоя и уменьшает его размерность (беря максимум каждого (2,2) блока пикселей, к примеру). Сверточный слой будет более детально рассмотрен в части §3.4.1.
	Аналогично CNN, рекуррентные сети специализируются на обработке последовательносей данных.

Рекуррентные нейронные сети (RNN). RNNs [Rumelhart et al., 1985; Werbos, 1988] являются моделями для обработки последовательностей, играющими ключевую роль в задаче онимания естественного языка, генерации текстов, обработке видео и множества других задач [Kalchbrenner and Blunsom, 2013; Mikolov et al., 2010; Sundermeyer et al., 2012; Sutskever et al., 2014]. Входом модели есть последовательность символов, где на каждом шаге простая нейронная сеть (RNN ячейка) применяется на символе, а также выходе этой же сети на предыдущем шаге. RNN являются мощной моделью, показывающей превосходные результаты на множестве задач.
	Сконцентрируемся на простой RNN модели для краткости описания. Имея входную последовательность x = [x1, ..., xT ] длины T, простая RNN получается путем повторяющегося использования функции f_h. Это порождает скрытое состояние h_t на шаге времени t:
                   h_t = f_h(x_t, h_{t−1}) = σ(x_tW_h + h_{t−1}U_h + b_h).
для некоторой нелинейной функции σ. Выход модели может быть определен, например, как 
                        yb = f_y(h_T) = h_TW_y + b_y.
Определение LSTM и GRU — более сложных RNN дано далее в разделе §3.4.2.


1.2 Неопределенность модели

Модели описанные выше могут быть применены в различных областях, начиная от определения рака кожи по изображению пораженного участка, управления беспилотным автомобилем и заканчивая классификацией породы собак на вебсайте, куда пользователи загружают фото своих питомцев. Для примера, имея несколько изображений пород собак как тренировочный набор данных, когда пользователь загружает фото своей собаки, гипотетический вебсайт должен вернуть предсказание с достаточно высокой вероятностью. Но что случится, если пользователь загрузит фото кошки и попросит сайт определить породу собаки?
	Описанный выше пример является примером тестовых данных полученных извне распределения (_переработать_). Модель тренировалась на фото собак различных пород и, есть надежда, обучилась определять различия среди них. Но модель никогда не видела кошек ранее и фото кошки находится вне распределения данных, на которых обучалась модель. Этот иллюстративный пример может быть расширен на более серьезные случаи, такие как МРТ-сканы со структурами, которые ранее не были учтены системой диагностирования, или условия, на которых система управления беспилотным автомобилем не обучалась. Возможное желаемое поведение модели в подобных случаях было бы вернуть предсказание (попытку экстраполировать точку вне известных данных), а также информацию, что входные данные лежат вне известного распределения (см. простую иллюстрацию для этого случая на рис. 1.2). Т.е. мы хотим чтобы наша модель обладала некоторым значением, которое бы несло в себе высокое значение неопределенности в подобных случаях (иначе говоря, низкую уверенность).
	Другие ситуации, которые могут привести к неопределенности включают:
* шумные данные (наши наблюдаемые классы могут быть шумными, например как результат неточных измерений, приводя к алеаторической неопределенности);
* неопределенность в параметрах модели, которые наилучшим образом описывают наблюдаемые данные (большое количество моделей могут обьяснить заданный набор данных, в этом случае мы будем неуверенны какой из набора параметров выбрать);
* структурная неопределенность (какую структуру модели нужно использовать? как точно определить нашу модель чтобы интерполировать/экстраполировать хорошо?).

	Последние две ситуации могут быть сгруппированы как неопределенность модели (или же эпистемологическую неопределенность). Алеаторическая и эпистемологическая неопределенность могут быть использованы чтобы получить предсказательную неопределенность, нашу уверенность в предсказании.

Рис. 1.2 Предсказанное среднее и неопределенности на наборе данный Mauna Loa концентрации CO2 для различных моделей на тестовых точках x*, лежащих вне наблюдаемого распределения. Красным выделена наблюдаемая функция(слева от пунктирной линии); синяя линия - предсказанное среднее плюс/минус два стандартных отклонения. Различными градациями синего обозначены половины стандартного отклонения. Красной штриховой линией обозначена точка далеко за пределами данных: стандартная модель глубокого обучения уверенно предсказывает необоснованное значение точки; вероятностная модель также предсказывает необоснованное значение, но в дополнение дает информацию, что модель неуверенна относительно предсказания.

Замечание (относительно терминологии). Слово эпистемологический происходит от греческого "episteme" - "знание", т.е. эпистемологическая неопределенность это "неопределенность знания". Алеаторический происходит от латинского "aleator”, или же “игрок в кости”, т.е. алеаторическая неопределенность это "неопределенность игрока в кости". Эпистемологическая и алеаторическая неопределенности иногда упоминаются как поддающиеся и не поддающиеся сокращению неопределенности соответсвенно, так как эпистемологическая неопределенность может быть сокращена получением большего количества данных (знаний), в то время как алеаторическая не может (стохастичность бросания кости не может быть уменьшена наблюдением за большим количеством результатов бросков). Однако мы не будем использовать эту терминологию, так как алеаторическая неопределенность может быть также рассмотрена как поддающейся сокращению через увеличение точности измерений, т.е. путем изменения системы в которой мы проводим эксперимент.

	Информация о неопределенности часто используется в науках о жизни, как описано в статье Herzog and Ostwald [2013]; Krzywinski and Altman [2013]; Nuzzo [2014], забавный случай также упоминается в [Trafimow and Marks, 2015]. В подобных областях довольно важно количественно определить нашу уверенность относительно предсказания модели. Неопределенность также важна практикам. Понимание того является ли модель неуверенной или ошибочно слишком уверенной (к примеру оценка неуверенности слишком мала) может помочь улучшить ее работу. Узнав, что тестовые данные далеко от тренировочных, мы можем, к примеру, дополнить тренировочные данные.
	Но, возможно, что более важно, информация о неопределенность модели может быть использована в системах, принимающих решение способные повлиять на человеческую жизнь, прямо или косвенно, как описано ниже.

1.3 Неопределенность модели и безопасность ИИ

С недавним успехом инженерии в области машинного обучения, системы которые ранее применялись лишь к маленьким объемам данных теперь применяются в реальных условиях. Среди них есть ситуации в которых контроль передан автоматизированной системе в ситуациях, которых есть вероятность угрозы жизни человеку. Это включает в себя автоматизированное принятие решений или рекомендационные системы в медицине, автономное управление дронами и беспилотные автомобили, возможность влиять на глобальную экономику через высокочастотный трейдинг, а также через контроль критически-важных систем. Все это может рассматриваться под понятием безопасности ИИ.
	Эта интерпретация безопасности ИИ немного отличается от той, которая дается в областях, обычно связанных с обучением с подкреплением (RL). Например, некоторые больше уделяют внимание созданию среды для самообучающихся агентов так чтобы не позволять им использовать недостатки процесса обучения как такового (такие как "хакинг награды"; см например [Amodei et al., 2016]). В противоположность, я буду рассматривать сценарии, в которых определенные решения, принятые моделью машинного обучения натренированной методом обучения с учителем, ставят под угрозу человеческую жизнь (например сценарии в которых некорректно соотнесенные входы выходам модели могт привести к нежелательным последовательностям). В некоторых из этих сценариев решение полагаться на неопределенность модели чтобы адаптировать процесс принятия решения - ключ к недопущению нежелательного поведения.

1.3.1 Врач диагностирующий пациента

Когда врач советует пациенту использовать определенные лекарства основываясь на медицинских показаниях, обычно он полагается на экспертные заключения в них. Тем не менее, с введением таких систем как автоматизированное обнаружение рака, основанное на МРТ сканировании, этот процесс может стать куда более сложным. Даже под руководством эксперта, такая система может иметь перекосы, влияющие на суждения эксперта. Система, сталкиваясь с тестовыми данными, лежащими за пределами ее распределения данных может запросто дать необоснованный прогноз, и, как следствие, неправомерное предвзятое мнение эксперта. Однако, имея уверенность модели, эксперт может быть уведомлен о ситуациях, когда система просто угадывает.

1.3.2 Беспилотные автомобили

Беспилотные системы могут быть разных видов, начиная от робота-пылесоса, ездящего по полу, до беспилотного автомобиля, перевозящего людей и товары из одного места в другое. Эти системы могут по большей части разделены на две группы: базирующиеся на правилах для контроля их поведения и адаптирующиеся относительно среды своего пребывания. Обе группы могут использовать методы машинного обучения. Первая группа через низкоуровневое использование алгоритмов машинного обучения для выделения признаков, а вторая через обучение с подкреплением.
	В беспилотных автомобилях, метод выделение низкоуровневых признаков такой как сегментация и локализация изображения используются для обработки сенсорной информации [Bojarski et al., 2016]. Выход такой модели затем скармливается высокоуровневой процедуре принятия решений. Этот высокоуровневый процесс может быть сделан через экспертную систему, опирающуюся, например на фиксированный набор правил ("если велосипедист находится слева от вас, не поворачивать налево"). Однако, ошибки сделанные низкоуровневыми компонентами машинного обучения могут по цепочке привести к неверному принятию решения и разрушительным последствиям. Одним из конкретных примеров такого риска, в системе содействия водителю, является сбой в низкоуровневом выделении компонент для различения белой полосы поворачивающего грузовика от яркого неба, повлекшего за собой первый летальный исход в системах содействия водителю [NHTSA, 2017]. В подобных модульных системах, было бы здраво использовать уверенность низкоуровневых компонент и делать высокоуровневые решения используя эту информацию. Например, система сегментации, которая бы идентифицировала неуверенность в различении между небом и другим автомобилем могла бы предупредить водителя о необходимости взяться за руль.

1.3.3 Критические системы и высокочастотный трейдинг

В качестве последнего примера, интересно отметить что контроль над критическими системами медленно подменяется системами машинного обучения. Это может случиться на почте, сортируя почту по почтовому коду [LeCun and Cortes, 1998; LeCun et al., 1998], или на атомной станции в системах, ответственных за критические инструкции [Linda et al., 2009]. Даже в высокоуровневом трейдинге, где компьютеры берут под контроль системы, способные потенциально дестабилизировать целые экономические рынки: делая необычные действия можно привести к бедствию. Одним из возможных решений, когда используется система, основанная на правилах, это полагаться на формальную систему верификации. Такие системы позволяют разработчику проверять работает ли система как ожидается перед ее внедрением. Но системы, основанные на машинном обучении, не позволяют этого делать. Что должна выдавать система в случае когда мы не уверены в наших результатах?
	Имея уверенность модели, одним из возможных решений было бы обрабатывать неуверенные результаты отдельно. В случае критических систем, мы вероятно хотели бы передать входную информаци человеку для принятия решения. Как альтернатива, можно использовать простую и быструю модель для предсказания и более сложную, но медленную, модель только для случаев, в которых слабая модель не уверена.
	В этой работе мы разрабатываем метод для определения уверенности модели глубокого обучения, который может быть применен в сценариях, описанных выше. Это будет сделано методом, который можно применить для уже существующих моделей. Это позволит использовать существующие системы, доказавшие свою полезность, и для которых уже сделан большой обьем исследований. Конкретный пример использования этой разработки для случаев, описанных выше, будет описан в разделе §5.1.

1.4 Прикладные приложения неопределенности модели

Помимо безопасности ИИ, также существует множество приложений, которые базируются на неопределенности модели. Эти приложения включают в себя определение по каким данным обучаться или же исследование эффективности агента в среде. Общим для этих двух задач является обучение малым объемом данных. Это часто необходимо в случаях, когда сбор данных является дорогим (например в случаях разметки каждого отдельного примера экспертом), или времязатратным (например когда нужно выполнить эксперимент множество раз).

1.4.1 Активное обучение

Как мы можем использовать машинное обучение для помощи экспертам, работающим в трудных областях? Одним из подходов является автоматизация небольших частей экспертной деятельности, таких как рутинный подсчет клеток, или диагностика рака по МРТ сканам. Тем не менее это может быть тяжелой проблемой для машинного обучения. Много алгоритмов машинного обучения, включая глубокое обучение. часто требуют большого числа размеченных данных чтобы иметь высокую обобщающую способность. Количество требуемых размеченных данных возрастает в зависимости от сложности проблемы и сложности входных данных: входные изображения для примера часто требуют для обработки большие модели и как следствие больших объемов данных (Krizhevsky et al. [2012] например использовал тысячи гигабайт размеченных изображений). Для автоматизации анализа МРТ-сканов, потребуется разметить экспертом большое количество данных, отмечая есть ли у пациента рак. Но время экспертов дорого и зачастую получение достаточного количества требуемых данных не достижимо. Как можно чему-то научиться в условиях малых данных и когда знания эксперта стоят дорого?
	Одним из возможных подходов - положиться на активное обучение [Settles, 2010]. В этом виде обучения модель сама выбирает какие данные из неразмеченных являются наиболее информативными и затем спрашивает "оракула" (например человека-аннотатора) чтобы тот разметил только эти точки. Выбор точек для разметки происходит через функцию приобретения информации, которая ранжирует точки основываясь на их потенциальной информативности. Существуют различные функции приобретения информации и многие из них используют неопределенность модели относительно неразмеченных данных для того чтобы определить их потенциальную информативность [Houlsby et al., 2011]. Используя этот метод мы можем уменьшить на порядок количество необходимых данных, в то же время имея хорошие характеристики модели )как мы увидим ниже в разделе §5.2).
	Возвращаясь к примеру выше о диагностике рака по МРТ-сканам, мы будем искать модель, которая будет давать хорошие оценки неопределенности для изображений и полагаться на них чтобы спроектировать хорошую функцию приобретения информации. Глубокое обучение дает превосходный метод для обработки изображений с хорошей генерализацией, но требует огромного объема размеченных данных и не предоставляет оценку неопределенности. В этой работе мы сфокусируемся на разработке расширения для таких моделей при малых данных, дающих хорошую уверенность моделей. С этими методами мы продемонстрируем достижимость идей описанных выше о активном обучении (раздел §5.2, совместная работа с Riashat Islam как часть его магистерского проекта).

1.4.2 Эффективное изучение в глубоком обучении с подкреплением

Алгоритмы обучения с подкреплением (RL) учится выполнять задачи методом проб и ошибок, примерно также как дети учатся ездить на велосипеде [Sutton and Barto, 1998]. Однако пробы и ошибки в задачах управления из реальной жизни зачастую включают время и ресурсы, которые мы бы не хотели тратить впустую. Иначе говоря, число проб и ошибок скорее всего ограниченно в связи с износом системы, делая эффективность относительно данных критически важной.
	В качестве несложного введения в обучение с подкреплением, представим себе агента (например робот-пылесос) которому требуется узнать о среде в которой он находится (жилая комната) основываясь на действиях (езда в различных направлениях). Он может решить поехать вперед и врезаться в стену. Поощряя пылесос не врезаться в стену наградой, со временем он научиться избегать их в поисках награды, балансирую между изучением и использованием уже известных знаний.
	Недавние достижения в глубоком обучении для RL-ситем (известными как глубокое RL) продемонстрировали впечатляющие результаты в игре [Mnih et al., 2013]. Такие подходы использовали НС с функцией аппроксимации на основе Q-занчения. Существуют функции, которые оценивают количество различных действий, которые агент может сделать. Жадный эпсилон-поиск часто используется при выборе действия агента с некоторой вероятностью либо исследовании в другом случае. Но с информацией о неопределенности агент может решить когда использовать знания, а когда делать исследование окружающей среды. С оценкой неопределенности по функции Q-значения, техники вроде томпсоновкого семплинга [Thompson, 1933] могут быть использованы для более быстрого обучения. Это будет продемонстрировано ниже в разделе §5.3.
	И хотя методы открытия, такие как томпсоновский семплинг, могут помочь обучаться лучшим правилам быстрее, намного более значительное улучшение в эффективности использования данных может быть достигнуто за счет моделирования динамики системы [Atkeson and Santamaria, 1997]. Динамическая модель позволяет агенту обобщать свое знание о системе динамически о других, не наблюдаемых, состояниях. Вероятностная модель динамики позволяет агенту учитывать неопределенность в перемещении через планирование и предсказание, увеличивая эффективность по данным еще больше. PILCO [Deisenroth and Rasmussen, 2011], к примеру, является эффективным поисковым алгоритмом, базирующимся на принципах моделей, эффективных относительно данных. PILCO аналитически распространяет неопределенность распределения состояния через динамическую модель гауссовского процесса. Это делается путем рекурсивного распространения выходного распределения состояний (неопределенность выходов) за единицу времени в качестве входного распределения состояний (неопределенности входов) к следующему шагу, до тех пор до некоторого горизонта времени T. Это позволяет агенту учитывать долгосрочные последствия (ожидаемое значение цены) конкретных параметров контроллера относительно всех возможных правдоподобных динамических моделей. PILCO полагается на Гауссов процесс (GP), который работает чрезвычайно хорошо для небольших объемов данных малой размерности, но масштабируется кубически с увеличением количества данных. Более того, в PILCO распространение распределения добавляет квадратичность в размерности наблюдаемых данных, делая трудным масштабировать эту модель на наблюдения больших порядков. Это делает затруднительным использование PILCO в задачах, требующих большого числа проб. Более того, PILCO не учитывает временные зависимости в неопределенности модели между успешными сменами состояний. Это означает, что PILCO недооценивает неопределенность состояний в будущих моментах времени [Deisenroth et al., 2015], что может привести к снижению качества.
	В разделе §5.4 мы попытаемся справиться с этими недостатками путем замены гауссова процесса в PILCO на байесовское глубокое обучение, в то же время сохраняя вероятностную природу модели и его эффективность по данным (совместная работа с Rowan McAllister и Carl Rasmussen [Gal et al., 2016]).

1.5 Неопределенность модели в глубоком обучении

Поняв, что уверенность модели - нужная для оценки величина, важно заметить, что большинство моделей глубокого обучения дают на выходе единственный вектор регрессии - среднюю величину относительно данных (как видно на рис 1.2). В моделях классификации, вектор вероятностей, полученный в конце обработки (выход софтмакса) зачастую ошибочно интерпретируют как уверенность модели в предсказании. Модель может быть не уверена даже тогда, когда выход софтмакса высокий (рис. 1.3). 

а) Некоторая функция f(x) как функция от данных x (вход софтмакса)
б) σ(f(x)) как функция от данных x (выход софтмакса)
Рис 1.3 Общее представление входа софтмакса и выхода идеализированной проблемы бинарной классификации. Тренировочные данные даны между штриховыми серыми линиями. Оценка функции в точках оценена жирной линией. Функция неопределенности показана как затененная область. Красной штриховой линией показана точка x*, лежащая далеко от тренировочных данных. Игнорируя функцию неопределенности, точка x* была классифицирована как класс 1 с вероятностью 1. 

Передавая точечную оценку функции (жирная линия на 1.3а) в софтмакс (жирная линия 1.3б) получаем экстраполяцию с необоснованно высокой уверенностью для точек, лежащих за пределами тренировочных данных. x* например была классифицирована как 1 с вероятностью 1. Однако, передавая распределение (затененная область 1.3а) в софтмакс (затененная область на 1.3б) лучше отражает неуверенность в классификации в точках далеко лежащих от тренировочных данных.
	И хотя современные модели глубокого обучения используемые на практике не учитывают уверенность модели, они тесно связаны с семейством вероятностных моделей, которые выводят вероятностные распределения над функциями: Гауссовы процессы. Имея НС, применяя распределение для каждого веса (стандартное нормальное распределение, к примеру), можно в пределе получить Гауссов процесс увеличивая количество весов до бесконечности (см. Neal [1995] or Williams [1997]). Для конечного количества весов, неуверенность модели может быть все также получена применением распределения над весами, такие модели называются байесовскими нейронными сетями. Они были детально изучены [MacKay, 1992b], работа, в дальнейшем расширенная [Neal, 1995]. Недавно эти идеи были воскрешены под именем вариационных методов [Blundell et al., 2015; Graves, 2011; Kingma and Welling, 2013] (хотя подобные методы, применяемые с баесовскими НС могут быть отслежены вплоть до работ Hinton и Van Camp [1993], а также Barber и Bishop [1998]). Но с некоторыми из этих моделей тяжело работать - они требуют куда больше параметров для оптимизации, и не стали популярными в сообществе глубокого обучения, вероятно из-за их практической ограниченности.
	Что же тогда нужно сделать для получения практического метода неопределенности модели? Одним из требований к такому методу является масштабируемость к большим данным и сложным моделям (таким как CNN и RNN). И что более важно,  будет непрактично изменять существующие хорошо изученные модели архитектур, а также часто непрактично работать с замысловатыми громоздкими методами, которые было бы трудно обьяснить не эксперту. Существующие методы для получения уверенности моделей часто не масштабируются к большому количеству данных и требуют от нас разработки новых моделей для существующих задач, для которых уже были разработаны хорошо работающие методы.
	Таким образом, мы сконцентрируемся на разработке практичного метода для получения уверенности модели глубокого обучения, метода, который хорошо вяжется с теоретическими основами теории вероятности и байесовского моделирования. Точнее, мы будем использовать методы стохастической регуляризации (SRT). SRT являются разработанными недавно методами для регуляризации моделей, чрезвычайно успешных в глубоком обучении и используются буквально во всех моделях глубокого обучения. Эти методы адаптируют выход модели стохастически как один из способов регуляризации (отсюда и название - стохастическая регуляризация) Это приводит к тому, что функция потерь становится случайной величиной, оптимизируемой используя методы стохастической не-выпуклой оптимизации. Популярные SRT включают в себя дропаут [Hinton et al., 2012], мультипликативный гауссов шум [Srivastava et al., 2014], dropConnect [Wan et al., 2013], и бесчисленное множество других новых методов ^4,5.
	Как мы увидим ниже, мы можем взять практически любую НС, натренированную SRT, и, имея на вход x* получить предсказание средней величины E[y∗] (ожидаемый результат модели при условии полученного входа) и вариацию предсказания Var[y∗] (насколько наша модель уверенна в своем предсказании). Чтобы их получить, мы симулируем выход имея на входе x*, используя SRT так, как если бы мы использовали модель для обучения (т.е. получали бы случайный выход путем стохастического прямого распространения). Мы повторяем этот процесс несколько раз (T повторения), получая i.i.d выходы {y􏰋1(x*), ..., y􏰋T (x*)}. Как будет объяснено ниже, это эмпирические сэмплы из приближенного распределения предсказаний. Мы можем получить эмпирическую оценку для предсказанного среднего нашего приближенного распределения также как и вариацию предсказаний:
                   E [ y* ] ≈ 1/T \sum {t=1..T} ( y_t(x*) )
                  Var[ y* ] ≈ τ^-1*I_D+ 1/T * \sum {t=1..T} ( y􏰋_t*(x*)T, y_t*􏰋t(x*) − E[y*] E[y] ).         (1.4)
Теоретическое обоснование этих двух простых уравнений будет дано в части 3.
	Уравнение (1.4) приводит к оценке неопределенности, которое является практичным имея больие модели и большие данные, мы можем применить его к моделям для обработки изображений, последовательностей данных и во многих других случаях, таких как обучение с подкреплением и активное обучение. Более того, комбинация этих методов позволяет нам выполнять задачи, ранее не выполнимые. Например, мы покажем ниже активное обучение на изображениях, задача чрезвычайно трудная в связи с отсутствием методов, дающих хорошую оценку неопределенности для изображений.

1.6 Структура диссертации

	Первая часть этой диссертации (части 3-5) будут посвящены на предоставлении метода для практической оценки неопределенности и демонстрации того как эти методы могут быть использованы во многих примерах. Эта часть будет легкой для понимания как для экспертов так и для не-экспертов в области. Вторая часть этой работы (глава 6) более глубоко рассматривает теоретические следствия работы выше. 
	Некоторая часто работы в этой диссертации была ранее представлена в [Gal, 2015; Gal and Ghahramani, 2015a,b,c,d, 2016a,b,c; Gal et al., 2016], но эта работа также содержит много новых частей. Наиболее важным является теоретический анализ оценки вариации по методу Монте Карло, используемого в вариационном выводе (§3.1.1–§3.1.2), обзор метрик неопределенности в задачах классификации (§3.3.1), эмпирический анализ различных априорных (§4.1) и апостериорных вероятностей в байесовских нейронных сетях для различных распределений (§4.2), новые количественные результаты сравнения дропаута с существующими методами (§4.3), методы для определения гетероскедастичной неопределенности в байесовских нейронных сетях (§4.6), приложения для активного обучения (§5.2), размышления о том что определяет как выглядит неопределенность модели (§6.1–§6.2), аналитический анализ приближенного распределения дропаута в байесовской линейной регрессии (§6.3), анализ ELBO-теста лог-вероятностной корреляции (§6.4), дискретные априорные модели (§6.5), интерпретация дропаута как промежуточную апостериорную вероятность в спайк и стаб априорных моделях (§6.6), а также процедуру оптимизации вероятностей дропаута, основанную на вариационной интерпретации для разделения различных источников неопределенности (§6.7).
	Код экспериментов, описанных в данной работе доступен по ссылке: https://github. com/yaringal.

Глава 2

Язык неопределенности

Чтобы формализировать наши рассуждения о неопределенности модели мы будем опираться на вероятностном моделировании, а точнее на байесовском моделировании. Байесовская теория вероятности дает нам инструментарий, который нужен нам для разработки нашей модели. Вместе с методами для приближенного вывода в байесовских моделях, в последующей главе мы дадим главные результаты этой работы. Но перед этим, давайте рассмотрим основные идеи, стоящие за байесовским моделированием, приближенный вывод и ключевую для нас модель: байесовская нейронная сеть.

2.1 Байесовское моделирование

Имея на входе вектор X = {x1, . . . , xN } и соотвествующий вектор выходов Y = {y1, . . . , yN }, в баесовской (параметрической) регрессии мы бы хотели найти такой параметр ω функции y = f^ω(x), которая вероятнее всего сгенерироваал наши выходы. Какие параметры скорее всего сгенерировали наши данные? Следуя байесовскому подходу, зададим априорную вероятность в пространстве параметров, p(ω). Это распределение описывает нашу априорное ожидание того какие параметры скорее всего породили наши данные перед тем как мы увидели какие-либо точки. Далее необходимо задать распределение правдоподобия p(y|x, ω) — вероятностную модель, которая при заданных входах сгенерировала выходы имея заданные параметры ω.
	Для классификации в качестве функции правдоподобия можно использовать софтмакс,
􏰁              􏰂  p(y=d|x,ω) =􏰅 exp(f_d^ω(x)) / \sum{d′} exp(f_d′^ω(x))
а для регрессии гауссово распределение:
		p􏰁(y|x,ω􏰂) = N(y;f^ω(x),τ^−1 I) 					(2.1)
с точностью модели τ. Это можно рассматривать как искажение выходов модели при ошибках наблюдений с вариацией τ^−1.
	Имея набор данных X, Y, мы можем найти апостериорное распределение в пространстве параметров используя теорему Байеса:
		p(ω|X, Y) = p(Y|X, ω)p(ω) / p(Y|X)
Это распределение описывает наиболее вероятные параметры функции при наблюдении данных. Имея их можно предсказать выход для новой точки x* путем интегрирования
		p(y∗|x∗,X,Y)=􏰊 \integral( p(y∗|x∗,ω)p(ω|X,Y)dω).
Этот процесс известен как вывод.
	Ключевым компонентом в подсчете апостериорной вероятности является нормирующий член, также известный как свидетельство модели (англ. model evidence):
		p(Y|X) = \integral ( p(Y|X, ω)p(ω)dω ). 			(2.2)
Это интегрирование также известно как маргинализация правдоподобия по ω, от которой происходит другое название для свидетельства модели: мар правдоподобие (англ. marginal likelihood). Маргинализацию можно провести анаитически для простых моделей вроде байесовской линейной регрессии. В таких моделях правдоподобие является сопряжением к априорной вероятности и может быть проинтегрирована используя известные методы исчисления. Маргинализация - основа основ байесовского моделирования, и в идеальном случае мы бы хотели маргинализировать по всем случайным величинам, т.е. усреднить по всем возможным параметрам модели ω, взвешенных по вероятности p(ω).
	Однако для более интересных моделей (даже для регрессии базисной функции, когда базисная функция не фиксирована) такая маргинализация не может быть аналитически найдена. В таких случаях нужна аппроксимация. 

2.1.1 Вариационный вывод

Истинная апостриорная вероятность p(ω|X, Y) зачастую не может быть вычислена аналитически. Вместо этого иы задаем приближенное вариационное распределение qθ(ω), пааметризованное по θ, которую легко вычислять. От приближенного распределения требуется быть как можно ближе к апостериорному распределению оригинальной модели. Таким образом мы минимизируем дивергенцию Кульбака-Лейблера (Kullback–Leibler (KL) divergence [Kullback, 1959; Kullback and Leibler, 1951]) по θ, которая интуитивно оценивает близость двух распределений:
		KL(q_θ(ω) || p(ω|X, Y)) = \integral􏰊(  q_θ(ω) log ( q_θ(ω) / p(ω|X, Y) ) dω.		(2.3)
Заметим, что этот интеграл задан только когда q_θ(ω) - абсолютно непрерывная при p(ω|X,Y) (т.е. когда для каждого измеримого множества A, из p(A|X,Y) = 0 слдует что qθ(A) = 0). Мы обозначили q_θ∗(ω) как минимум целевой функции (часто локальный).
	Минимизация KL-дивергенции позволяет нам аппроксимировать функцию предсказания как 
		p(y∗|x∗,X,Y)≈􏰊 p(y∗|x∗, ω)qθ_∗(ω)dω =: q_θ∗(y∗|x∗). 					(2.4)
Минимизация KL-дивергенции эквивалентна максимизации нижней границы свидетельства (the evidence lower bound (ELBO)) по вариационным параметрам заданных qθ(ω),􏰊
  L_VI(θ) := \integral ( q_θ(ω) log p(Y|X, ω) ) dω − KL( q_θ(ω) || p(ω) ) ≤ log p(Y|X) = log evidence,  (2.5)
которая задает целевую функцию, на которую мы будем в дальнейшем ссылаться. Максимизация первого члена последнего уравнения (называемую ожидаемым лог-правдоподобием) спомобствует q_θ(ω) хорошо объяснять данные, в то время как минимизация второго члена (известного как априорная вероятность KL) способствует чтобы qθ(ω) была как можно ближе к априорной вероятности. Это работает по принципе "бритвы Оккама", штрафуя сложные распределения q_θ(ω).
	Эта процедура также известна как вариационный вывод (variational inference (VI)), стандартный метод в байесовском моделировании [Jordan et al., 1999]. Вариационный вывод заменяет собой байесовскую маргинализацию модели оптиимизацией, т.е. мы заменяем вычисление интеграла на вычисление производных. Однако, по сравнению к оптимизационным подходам, которые зачастую используются в глубоком обучении, в этом случае мы оптимизируем распределение вместо точечных оценок. Этот подход сохраняет множество преимуществ байесовского моделирования (таких как баланс между сложностью модели и модели, которая хорошо обьясняет данные) и приводит к вероятностной модели, которая способна рассчитывать неопределенность.
	Подсчет производных часто намного более прост чем вычисление интегралов, что делает множество аппроксимаций разрешимыми. Однако даже хотя эта процедура делает вывод аналитическим для широкого класса модеелй, у нее все еще множество недостатков. Этот метод не масштабируется на большие данные (подсчет 􏰇 \integral ( q_θ(ω) log p(Y|X, ω) ) dω требует вычислений по всем имеющимся данным), а также он не адаптируется к более сложным моделям (моделям, в которых последний интеграл не может быть подсчитан аналитически). Благодаря успехам последних лет в области VI удалось преодолеть многие из этих трудностей, и мы вернемся к этой теме позже в разделе §3.1. Но вначале рассмотрим ключевую по важности для нас модель: байесовскую нейронную сеть.

2.2 Байесовские нейронные сети

Впервые предложенная в 90х и с тех пор интенсивно изученная [MacKay, 1992b; Neal, 1995], байесовская нейронная сеть (BNN, байесовская НС) предоставляет вероятностную интерпретацию моделей глубокого обучения путем задания распределений весами моделей. Модель является устойчивой к переобучению, дает оценку неопределенности и может с легкостью обучиться на малом объеме данных.
	Байесовская НС задает априорное распределение в весах нейронной сети, что включает в себя распределение на множестве параметров функций. Имея матрицу весов W_i и вектор смещения b_i для слоя i, мы обычно размещаем задаем стандартное матричное гауссово априорное распределение на матрице весов, p(Wi) = N (0, I), и полагаем для простоты точечную оценку для вектора смещения. Правдоподобие обычно задается как в литературе по байесовскому обучению (через функцию софтмакса или гауссовым правдоподобием, §2.1).
	Байесовские НС просты в формулировании, но тяжелы для вывода. Многие пытались это делать с различной степенью успешности. Далее идет обзор таких попыток.

2.2.1 Краткая история

В работе AT&T Bell Laboratories в 1987, Denker, Schwartz, Wittner, Solla, Howard, Jackel, and Hopfield [1987] рассмотрели общую проблему обучения на примерах. Они расширили уже имеющуюся огромную базу литературы исследований нейронных сетей и предложили новый метод их тренировки. По сути, Denker et al. [1987, страница 904] предложил использовать распределения на множестве весов (и использовал равномерное распределение на небольшом пространстве). Задавая все возможные (бинарные) входы {x1, ..., xN } они задали соответствие каждой конфигурации весов множество выходов {y􏰋1,...,y􏰋N}. Это позволило им проинтегрировать взять интеграл по всем весам и получить маргинальную вероятность для каждого множества {y􏰋1,...,y􏰋N}. Имея наблюдаемые данные, вероятность несовместимых с ними весов были выставлены в 0, приводя к обновлению маргинальной вероятности для каждого множества {y􏰋1,...,y􏰋N}. Эти маргинальные вероятности были использованы для расчета эффективности сети (путем расчета ее энтропии).
	Работая также в AT&T Bell Laboratories, Tishby, Levin, and Solla [1989] расширили идеи Denker и др. [1987] и разработали статистические методы для вывода обобщающей ошибки сети. Из того что мне удалось найти, это было первое из упоминаний того что сейчас называется "Байесовская нейронная сеть". Tishby и др. [1989] показали, что единственной статистической интерпретацией евклидовой функции потерь в НС является максимальное правдоподобие при гауссовом правдоподобии по весам. Они предложили задать априорную вероятность на весах нейронной сети и показали, что вывод может быть теоретически произведен применением теоремы Байеса. Это было использовано для получения численной оценки, основанной только на тренировочных данных, которая будет коррелировать с ошибкой обобщения на тестовых данных (однако, проблема вывода с практической стороны была упущена из виду).
	В других работах, сделанных в AT&T Bell Laboratories, Denker и LeCun [1991] расширили идеи Tishby и др. [1989] и предложили использовать метод лапласа для аппроксимации апостериорных вероятностей в Байесовской НС. Denker и LeCun [1991] использовали (тогда еще) новую методику обратного распространения ошибки и оптимизировали веса НС для нахождения моды. Затем они подогнали гауссову модель для получения моды, с шириной гауссианы определенной гессианом правдоподобия в этой моде. (??? што блять).
	Работая в California Institute of Technology, MacKay [1992b] провел обширное исследование байесовских НС. Он указал на целесообразность использования свидетельство модели для сравнения моделей и получил значения используя метод аппроксимации предложенный Denker и LeCun [1991]. Используя серию экспериментов с разными размерами модели и конфигурациями, MacKay [1992b] показал что свидетельство модели коррелирует с ошибкой обобщения и поэтому может быть использована для выбора размера модели. MacKay [1992b] показал, что неправильное задание модели может привести к неверной работе Байесовских выводов, при которых свидетельство модели нечего не говорит об обобщающей способности модели. Как он показал, это может случиться например для примера, когда априорные вероятности многих слоев весов связаны друг с другом, и как следствие низкая априорная вероятность будет необоснованно дана моделям с огромными значениями весов и в то же время маленькими значениями весов на выходном слое. (??? чаво???)
	Как один из путей регуляризации, Hinton и Van Camp [1993] (работая в Торонто) предложили использовать минимальную описательную длину (minimum description length, MDL) для штрафования высокого объема информации, содержащегося в весах нейронной сети. Они показали, что для НС с одним скрытым слоем возможно посчитать из предложенную (и в некотором роде только для этого случая) целевую функцию аналитически. Этот метод может быть рассмотрен как первыя аппроксимация вариационного вывода в Байесовской НС, и пусть даже эта методика и базировалась на теоретических основах информационной теории, ее результат идентичен VI через ELBO (как будет показано ниже).
	В своей диссертации, Neal [1995] разработал альтернативное приближение вывода байесовской НС основанное на методе Монте Карло (MC). Гамильтоново Монте Карло (HMC, а также Hybrid Monte Carlo) было предложено для апостериорной вероятности, метод, основанный на динамической симуляции, который не основывался на предположении о априорной вероятности о форме апостериорного распределения. Neal [1995] предпринял попытку воспроизвести эксперимент MacKay [1992b], базирующийся на методе Лапласа [Denker and LeCun, 1991]. Neal [1995, стр 122] проверил некоторые эксперименты MacKay [1992b], но не смог воспроизвести другие, возможно из-за ошибки приближения метода Лапласа. В дополнение к этому, Neal [1995] далее исследует разные априорные распределения в байесовских НС, и показывает, что при ограниченном числе нейронов, модель сойдется к различным стабильным процессам, в зависимости от использованной априорной вероятности (например, модель сойдется к Гауссовому процессу, если будет использовано Гауссова априорная вероятность).
	Последняя ключевая разработка, касающейся нашей темы, проистекает из работы Barber и Bishop [1998]. В этой работе Barber и Bishop [1998] разработали приближение MDL Hinton и Van Camp [1993] используя интерпретацию VI и заменили диагональную ковариационную матрицу Hinton-а и Van Camp-а [1993] на полную ковариационную матрицу. Barber и Bishop [1998] подчеркнули тот факт, что полученная целевая функция формирует нижнюю границу свидетельствам модели. И последнее, Barber и Bishop [1998] поместили гамма априорные вероятности как гиперпараметры сети. Затем они провели вариационный вывод на распределении произвольной формы по гиперпараметрам и вывели их оптимальную форму. Это позволило свидетельству модели (нижней границе которую дает ELBO) оставаться константой при изменении значений гипермапаметров, так как они всегда оставались усредненными в соответствии к их приближенному распределению.

Замечание (мультимодальное или унимодальное приближенное распределение?): MacKay [1992b] использовал унимодальное гауссово распределение чтобы подогнать апостериорную вероятность и сделал вывод что этого дает намного больше чем оценка наибольшего правдоподобия (MLE). Это потому что ширина подогнанной гауссианы ведет себя подобно "бритве Оккама" и штрафует сложные модели (по сути считая отношение между объемом параметров апострериорного и априорного распределений). Neal [1995] раскритиковал такое упрощенное приближение и аргуметировал что оно работает только для проблем малой размерности (и таким образом мы должны использовать HMC, которое не делает никаких предположений относительное структуры апостериорной вероятности и способно аппроксимировать сложные распределения апостериорной и предсказательной вероятностей.
Однако подгон апостериорной вероятности на весах в байесовской НС унимодальным распределением вовсе не означает что и выходное распределение будет унимодальным. Представьте для простоты что признаки из первого слоя описываются унимодальным распеределением (например равномерным) и пусть, в качестве аргумента, следующий слой смоделирован дельта-распределением (или гауссиана с очень маленькой вариацией). Имея достаточное количество слоев мы можем аппроксимировать любую функцию с любой точностью, включая инверсную кумулятивную функцию распределения (CDF) любого мультимодального распределения. Пропуская унимодальный выход первого слоя через остальные слоя, трансформируя его в CDF, что дает нам предсказанное мультимодальное распределение.

	Эти подходы покаывают важные первые шаги на пути практически применимого вывода в байесовских НС. Но их было трудно адаптировать к современным нуждам, найденным в этой области. Далее мы рассмотрим более современные подходы для приближенного вывода в байесовских НС.

2.2.2 Современный приближенный вывод
	Современные исследования байесовских НС часто основаны либо на разного рода вариационном выводе либо на методах, основанных на выборке. Каждый из подходов имеет свои преимущества и ограничения. Далее мы рассмотрим недавно предложенные методы.
	Для вариационного вывода, современные подходы следуют близко за работой Hinton и Van Camp [1993]. Эта работа базируется на полностью факторизированном приближении - приближенное распределенияе предполагает независимость каждого скаляра весов в каждом слое от других весов. Мы рассмотрим этот метод более детально с точки зрения VI. А затем работами, которые его расширяют.
	Вспомним что нам нужно найти распределение матриц весов (параметризирующих нашу функцию), которая сгенерировала наши данные. Это апостериорное распределение на весах имея наблюдения X, Y: p(ω|X, Y). Это апостериорное распределение не может быть найдено в общем виде и мы используем вариационный вывод для его приближения. Для этого нам нужно задать распределение вариационного приближения qθ(ω) и мимнимизировать KL-дивергенцию между приближенным распределением и полным впостериорным распределением:
	KL􏰁( q_θ(ω) || p(ω|X,Y) )􏰂 ∝ −􏰊\integral( q_θ(ω)log p(Y|X,ω) )dω + KL(q_θ(ω)||p(ω)) 	(2.6)
		= − \sum {i=1..N} \integral ( 􏰈q_θ(ω) log p( y_i | f^ω(x_i) ) )dω + KL(q_θ(ω) || p(ω))

где f^ω(x_i) - выход модели имея х_i на входе и с членами просуммированными в последнем уравнении - ожидаемое лог-правдоподобие. Hinton и Van Camp [1993] задают q_θ(ω) так чтобы факторизировать по весам:
	q_θ(ω) = \product {i=1..L} q_θ(W_i) = \product {i=1..L} \product {j=1..K_i} \product {k=1..K_(i+1)} q_m_ijk, σ_ijk(w_ijk) = \product {i,j,k} N(w_ijk; m_ijk ,σ_ijk^2 ).
Оптимизация целевой функции трудна, так как ожидаемое лог-правдоподобие не трудно найти для большинства моделей BNN структур. Поэтому Hinton и Van Camp [1993] только продемонстрировали метод на сети с одним скрытым слоем, в которой оптмизация целевой функции аналитична.
	Даже когда оптимизация аналитична, приближение может работать довольно плохо на практике. Это может быть обяснено тем что метод не учитывает важную информацию о корреляции весов. Barber и Bishop [1998], путем моделирования  корреляции между весами, сумел улучшить проделанное Hinton и Van Camp [1993]. Но за счет увеличения вычислительной сложности. Теперь метод требовал представление ковариационной матрицы с квадратичным числом весов модели. Это было непрактично для большинства современных моделей, так как число параметров модели в современных глубоких сетях имеет тенденцию быть так велико, как того позволяет оборудование. С дополнительным ограничением, повившимся в результате необходимости обрабатывать огромные количества данных, простой VI не может масштабироваться к современным потребностям и потому был практически забыт.
	В недавней работе,  Graves [2011] сделал попытку ответить на выше описанные вызовы. Graves [2011] использовал 


In recent work, Graves [2011]...
























    

































